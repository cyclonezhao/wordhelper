[
{"word":"probability density function,interpreted,likelihood","sentence":"In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.","desc":"概率密度函数"},
{"word":"statistics,kernel density estimation,non-parametric,inferences","sentence":"In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable. Kernel density estimation is a fundamental data smoothing problem where inferences about the population are made, based on a finite data sample.","desc":"核密度估计"},
{"word":"inductive bias,assumptions,subsumed", "sentence":"The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs given inputs that it has not encountered. The kind of necessary assumptions about the nature of the target function are subsumed in the phrase inductive bias.","desc": "归纳偏置；必要的假设也包含在内"},
{"word":"reorganized,flourish,tackling,solvable problems,benefited from,digitized,distribute", "sentence":"Machine learning, reorganized as a separate field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability theory.[11] It also benefited from the increasing availability of digitized information, and the ability to distribute it via the Internet.","desc": ""},
{"word":"emphasis,approach,rift,Probabilistic systems,plagued,theoretical,data acquisition,connectionism,disciplines,reinvention", "sentence":"However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[10]:488 By 1980, expert systems had come to dominate AI, and statistics was out of favor.[11] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[10]:708–710; 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including Hopfield, Rumelhart and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.","desc": "逻辑层面上的着重强调"},
{"word":"Backpropagation,shorthand,propagation", "sentence":"Backpropagation is a method used in artificial neural networks to calculate a gradient that is needed in the calculation of the weights to be used in the network.[1] Backpropagation is shorthand for \"the backward propagation of errors,\" since an error is computed at the output and distributed backwards throughout the network’s layers.[2] It is commonly used to train deep neural networks.","desc": ""},
{"word":"pioneer,endeavour,quest,academic discipline,symbolic,automated medical diagnosis", "sentence":"Arthur Samuel, an American pioneer in the field of computer gaming and artificial intelligence, coined the term \"Machine Learning\" in 1959 while at IBM[8]. As a scientific endeavour, machine learning grew out of the quest for artificial intelligence. Already in the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[9] Probabilistic reasoning was also employed, especially in automated medical diagnosis.","desc": "自动医疗诊断"}
]
